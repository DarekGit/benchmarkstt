{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the name entity\n",
    "from copy import deepcopy\n",
    "import re\n",
    "import benchmarkstt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some usefull functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the position of one NE \n",
    "# a NE can contains more than one word\n",
    "def find_pattern(search_list, named_entity):\n",
    "    entity = ''.join(named_entity).split(' ')\n",
    "    le = len(entity)\n",
    "    cursor = 0\n",
    "    idx_found = []\n",
    "    for idx, elt in enumerate(search_list):\n",
    "        if elt == entity[cursor]:\n",
    "            cursor += 1\n",
    "            if cursor == le:\n",
    "                idx_found.append([idx for idx in range(idx-le+1, idx-le+1+le)])\n",
    "                cursor = 0\n",
    "        else:\n",
    "            cursor = 0\n",
    "    return(idx_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all the words that are not a NE by 'x' \n",
    "def generate_list_x(list_parsed, named_entities, replacement = 'x'):\n",
    "\n",
    "    list_x = [replacement]*len(list_parsed)\n",
    "    index_entities = []\n",
    "\n",
    "    # detect the index of the entities\n",
    "    for entity in named_entities:\n",
    "        index_entity = find_pattern(list_parsed, entity)\n",
    "        index_entities.extend(index_entity)\n",
    "\n",
    "    # flatten\n",
    "    index_entities = [item for sublist in index_entities for item in sublist]\n",
    "\n",
    "    # just copy-past the entity found in the list with x\n",
    "    for k in index_entities:\n",
    "        list_x[k] = list_parsed[k]\n",
    "\n",
    "    return(list_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a list containing the detected NEs in list_parsed\n",
    "def generate_list_ne(list_parsed, named_entities):\n",
    "\n",
    "    list_ne = []\n",
    "    index_entities = []\n",
    "\n",
    "    for entity in named_entities:\n",
    "        index_entity = find_pattern(list_parsed, entity)\n",
    "        index_entities.extend(index_entity)\n",
    "\n",
    "    # sort on the position of the first part of the entity\n",
    "    index_entities.sort(key=lambda l: l[0])\n",
    "\n",
    "    # copy-past the entity found in the list with x\n",
    "    for k_list in index_entities:\n",
    "        list_ne.append(' '.join(list_parsed[k_list[0]:k_list[-1]+1]))\n",
    "\n",
    "    return(list_ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the NEER \n",
    "def wer_bag_ne(named_entities, list_hypothesis_ne, list_reference_ne):\n",
    "    neer = {}\n",
    "    neer_av = 0\n",
    "    for entity in named_entities:\n",
    "        count_hypothesis = list_hypothesis_ne.count(entity)\n",
    "        count_ref = list_reference_ne.count(entity)\n",
    "        neer[entity] = abs(count_ref-count_hypothesis)/count_ref\n",
    "        # accumulate the distance per entity\n",
    "        neer_av += count_ref * neer[entity]\n",
    "    neer_av = neer_av / len(list_reference_ne)\n",
    "    neer['av_neer'] = neer_av\n",
    "    return(neer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named entities definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_entities = [\"minister\", \"theresa may\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generates the files and lists for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_file = open(\"qt_kaldi_hypothesis_normalized.txt\")\n",
    "hypothesis_txt = hypothesis_file.read()\n",
    "hypothesis_file.close()\n",
    "reference_file = open(\"qt_reference_normalized.txt\")\n",
    "reference_txt = reference_file.read()\n",
    "reference_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean-up the reference files : erease spaces to make it clearer\n",
    "reference_txt = reference_txt.replace('\\n', ' ').replace('\\r', '')\n",
    "# supress multi space could be added as a regex\n",
    "reference_txt = re.sub('\\s+', ' ', reference_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the lists corresponding to the files\n",
    "hypothesis_list_full = hypothesis_txt.split(' ')\n",
    "reference_list_full = reference_txt.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_list = hypothesis_list_full[0:200]\n",
    "reference_list = reference_list_full[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all the words of the list by x except named entities\n",
    "list_hypothesis_x = generate_list_x(hypothesis_list, named_entities)\n",
    "list_reference_x = generate_list_x(reference_list, named_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extact the named entities\n",
    "list_hypothesis_ne = generate_list_ne(hypothesis_list, named_entities)\n",
    "list_reference_ne = generate_list_ne(reference_list, named_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 to compute WER from files with NE and x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================\n",
      "reference\n",
      "=======================================\n",
      "x x x x x x minister theresa may x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x minister theresa may x x x x x x x x x x x x minister x x x x x x x x x x\n",
      "\n",
      "=======================================\n",
      "hypothesis\n",
      "=======================================\n",
      "x x x minister theresa may x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x minister theresa may x x minister x x x x x x x x x x x x x x x x x x x x x x x x x x\n",
      "\n",
      "\n",
      "wer\n",
      "===\n",
      "\n",
      "0.160000\n",
      "\n",
      "diffcounts\n",
      "==========\n",
      "\n",
      "equal: 184\n",
      "replace: 0\n",
      "insert: 16\n",
      "delete: 16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute the wer with the published method\n",
    "# generate the str ...\n",
    "str_hypothesis_x = ' '.join(list_hypothesis_x)\n",
    "str_reference_x = ' '.join(list_reference_x)\n",
    "\n",
    "text_file = open(\"reference_x.txt\", \"w\")\n",
    "text_file.write(str_reference_x)\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(\"hypothesis_x.txt\", \"w\")\n",
    "text_file.write(str_hypothesis_x)\n",
    "text_file.close()\n",
    "\n",
    "print('=======================================')\n",
    "print('reference')\n",
    "print('=======================================')\n",
    "print(str_reference_x)\n",
    "print('')\n",
    "print('=======================================')\n",
    "print('hypothesis')\n",
    "print('=======================================')\n",
    "print(str_hypothesis_x)\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "!benchmarkstt - -reference reference_x.txt - -hypothesis hypothesis_x.txt - -wer - -diffcounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methode 2 computes the NEER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the alinment of the extracted entities\n",
      "============================================\n",
      "\n",
      "minister ------ minister\n",
      "theresa may ------ theresa may\n",
      "minister ------ minister\n",
      "theresa may ------ theresa may\n",
      "minister ------ minister\n"
     ]
    }
   ],
   "source": [
    "print('Check the alinment of the extracted entities')\n",
    "print('============================================')\n",
    "print('')\n",
    "for idx, elt in enumerate(list_reference_ne):\n",
    "    try:\n",
    "        print('{1} ------ {1}'.format(list_hypothesis_ne[idx], elt))\n",
    "    except:\n",
    "        print('{1} ------ {1}'.format('xx', elt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted NE from reference file\n",
      "['minister', 'theresa may', 'minister', 'theresa may', 'minister']\n",
      "\n",
      "Extracted NE from hypothesis file\n",
      "['minister', 'minister', 'minister', 'theresa may']\n"
     ]
    }
   ],
   "source": [
    "list_hypothesis_ne_error = deepcopy(list_hypothesis_ne)\n",
    "list_hypothesis_ne_error[1] = 'minister'\n",
    "list_hypothesis_ne_error.pop()\n",
    "\n",
    "print('Extracted NE from reference file')\n",
    "print(list_reference_ne)\n",
    "print('')\n",
    "print('Extracted NE from hypothesis file')\n",
    "print(list_hypothesis_ne_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minister theresa may minister theresa may minister\n",
      "\n",
      "minister minister minister theresa may\n",
      "\n",
      "wer\n",
      "===\n",
      "\n",
      "0.857143\n",
      "\n",
      "diffcounts\n",
      "==========\n",
      "\n",
      "equal: 3\n",
      "replace: 0\n",
      "insert: 2\n",
      "delete: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the wer takes into account the position of the named entity\n",
    "# wer on list of ne\n",
    "\n",
    "str_hypothesis_ne = ' '.join(list_hypothesis_ne_error)\n",
    "str_reference_ne = ' '.join(list_reference_ne)\n",
    "\n",
    "print(str_reference_ne)\n",
    "print('')\n",
    "print(str_hypothesis_ne)\n",
    "print('')\n",
    "\n",
    "# saves the files\n",
    "file = open(\"hypothesis_ne.txt\", \"w\")  # write mode\n",
    "file.write(str_hypothesis_ne)\n",
    "file.close()\n",
    "file = open(\"reference_ne.txt\", \"w\")  # write mode\n",
    "file.write(str_reference_ne)\n",
    "file.close()\n",
    "\n",
    "\n",
    "!benchmarkstt - -reference reference_ne.txt - -hypothesis hypothesis_ne.txt - -wer - -diffcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'minister': 0.0, 'theresa may': 0.5, 'av_neer': 0.2}\n"
     ]
    }
   ],
   "source": [
    "wer_ne = wer_bag_ne(\n",
    "    named_entities, list_hypothesis_ne_error, list_reference_ne)\n",
    "print(wer_ne)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
